{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513944eb",
   "metadata": {},
   "source": [
    "# Training a Tiny Language Model from Scratch\n",
    "\n",
    "This is a minimalistic example of training a language model from scratch using PyTorch. This code demonstrates:\n",
    "\n",
    "- Tokenizing a small dataset.\n",
    "- Converting the text into a sequence of integer indices.\n",
    "- Creating training samples for next-word prediction.\n",
    "- Defining a simple feedforward neural network model.\n",
    "- Training the model on the dataset.\n",
    "- Use the model to predict next words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d72b7",
   "metadata": {},
   "source": [
    "## Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12718224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Show current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90831664",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset\n",
    "\n",
    "We start with a very small dataset â€” a short story about three little pigs. This will be used for next-word prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a8795",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"once upon a time there were three little pigs who went out into the world \"\n",
    "    \"to build their own houses the first little pig built his house out of straw \"\n",
    "    \"the second little pig built his house out of sticks \"\n",
    "    \"the third little pig built his house out of bricks \"\n",
    "    \"one day a big bad wolf came along and saw the first little pig in his straw house \"\n",
    "    \"he knocked on the door and said little pig little pig let me come in \"\n",
    "    \"not by the hair of my chinny chin chin said the pig \"\n",
    "    \"then I'll huff and I'll puff and I'll blow your house in said the wolf \"\n",
    "    \"and he did the straw house blew down and the first little pig ran to his brother's house made of sticks \"\n",
    "    \"but the wolf followed and said little pigs little pigs let me come in \"\n",
    "    \"not by the hairs of our chinny chin chins they said \"\n",
    "    \"so the wolf huffed and puffed and blew the stick house down too \"\n",
    "    \"the two little pigs ran to their brother's house made of bricks \"\n",
    "    \"the wolf followed once more and said little pigs little pigs let me come in \"\n",
    "    \"not by the hairs of our chinny chin chins they said again \"\n",
    "    \"so the wolf huffed and puffed but this time he could not blow the house in \"\n",
    "    \"the brick house was strong and sturdy and the three little pigs were safe inside\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ff5f0",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Next, we tokenize the text by splitting it into words and assigning each unique word a numeric index. This builds our vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and assign indices\n",
    "words = list(set(text.split()))\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "vocab_size = len(words)\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "print(\"Sample word2idx mapping:\", dict(list(word2idx.items())[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7900a5",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "We convert the text into a sequence of integer indices based on the vocabulary created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88253cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text encoding\n",
    "encoded = [word2idx[w] for w in text.split()]\n",
    "print(\"Encoded sequence (first 10):\", encoded[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4235138",
   "metadata": {},
   "source": [
    "\n",
    "## Training Data Preparation\n",
    "\n",
    "We create input-output pairs using a fixed context window. Each input is a sequence of `context_size` words, and the target is the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a43ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create input-target pairs for training\n",
    "def get_batches(encoded, context_size=2):\n",
    "    \"\"\"\n",
    "    Creates input-target pairs for training.\n",
    "    Each input is a sequence of context_size words, \n",
    "    and the target is the next word.\n",
    "    \"\"\"\n",
    "    inputs, targets = [], []\n",
    "    for i in range(len(encoded) - context_size):\n",
    "        context = encoded[i:i+context_size]\n",
    "        target = encoded[i+context_size]\n",
    "        inputs.append(context)\n",
    "        targets.append(target)\n",
    "    return torch.tensor(inputs), torch.tensor(targets)\n",
    "\n",
    "x, y = get_batches(encoded)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"Example input-target pair:\", x[0], '->', y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3162d",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "We define a simple feedforward neural network model that uses word embeddings and a linear layer to predict the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for the TinyLLM model\n",
    "class TinyLLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, context_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim * context_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a738a8c",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "We initialize the model, optimizer, and loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ae5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define context size\n",
    "context_size = 2\n",
    "\n",
    "# Initialize model\n",
    "model = TinyLLM(vocab_size, \n",
    "                embed_dim=10, \n",
    "                context_size=context_size)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d55f6",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "The model is trained for a number of epochs using cross-entropy loss. The training process involves predicting the next word and updating the model weights accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a613348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(500):\n",
    "    logits = model(x)\n",
    "    loss = loss_fn(logits, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Final training loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f025b",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "We define a function to generate the next `n` words given a context of `context_size` words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da122af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the next n words\n",
    "def predict_next_n(context_words, n=3):\n",
    "    \"\"\"\n",
    "    Predict the next n words given a context of words.\n",
    "    \"\"\"\n",
    "    result = context_words.copy()\n",
    "    for _ in range(n):\n",
    "        context_idx = torch.tensor([[word2idx[w] for w in result[-context_size:]]])\n",
    "        logits = model(context_idx)\n",
    "        predicted_idx = torch.argmax(logits, dim=1).item()\n",
    "        predicted_word = idx2word[predicted_idx]\n",
    "        result.append(predicted_word)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example prediction\n",
    "print(\"Prediction example:\", predict_next_n([\"one\", \"day\"], n=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218008e",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info-- (please always provide this at the end of each notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b61ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
